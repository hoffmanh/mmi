{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df85d5ae",
   "metadata": {},
   "source": [
    "# MMI prediction\n",
    "\n",
    "## 6. Testing\n",
    "- Load test data and models\n",
    "- Test models\n",
    "- Get permutation feature importance values\n",
    "- Evaluate performance of individual risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace6adc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e9b070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 77 testing samples\n"
     ]
    }
   ],
   "source": [
    "# load testing data\n",
    "\n",
    "X_test = pd.read_pickle('X_test_processed.pkl')\n",
    "y_test = pd.read_pickle('y_test.pkl')\n",
    "print('there are {} testing samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61f4985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    66\n",
       "Y    11\n",
       "Name: malig_infarct, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9f5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240c2a61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_rf.sav',\n",
       " 'final_logreg.sav',\n",
       " 'final_mlp.h5',\n",
       " 'final_mlp',\n",
       " 'final_svm.sav',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6b0ad",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5fc560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load models\n",
    "\n",
    "def load_models():\n",
    "    final_models = []\n",
    "\n",
    "    for model in os.listdir('models'):\n",
    "        if model.endswith('.sav'):\n",
    "            test_model = load(open(os.path.join('models', model), 'rb'))\n",
    "            final_models.append((model.split('.')[0], test_model))\n",
    "        if model == 'final_mlp':\n",
    "            test_model = load_model(os.path.join('models', model))\n",
    "            final_models.append((model, test_model))\n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5ba7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "\n",
    "final_models = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f20fcab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('final_rf',\n",
       "  RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                         n_estimators=140)),\n",
       " ('final_logreg', LogisticRegression(C=0.1, max_iter=1000)),\n",
       " ('final_mlp', <keras.engine.functional.Functional at 0x7f9443e57100>),\n",
       " ('final_svm', SVC(C=1, gamma=0.0001, probability=True))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74702a",
   "metadata": {},
   "source": [
    "## Test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "881f179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to evaluate models multiple times with bootstrapping and save results\n",
    "\n",
    "def eval_model(final_models, n_iterations, fname):\n",
    "\n",
    "    # create empty results dicts for each metric\n",
    "    results_auc = {'final_rf': [], 'final_logreg': [], 'final_mlp': [], 'final_svm': []}\n",
    "    results_prec = {'final_rf': [], 'final_logreg': [], 'final_mlp': [], 'final_svm': []}\n",
    "    results_recall = {'final_rf': [], 'final_logreg': [], 'final_mlp': [], 'final_svm': []}\n",
    "    results_f1 = {'final_rf': [], 'final_logreg': [], 'final_mlp': [], 'final_svm': []}\n",
    "    results_acc = {'final_rf': [], 'final_logreg': [], 'final_mlp': [], 'final_svm': []}\n",
    "    \n",
    "    # bootstrap resample\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('evaluating iteration no. {}...'.format(i))\n",
    "        \n",
    "        X_test_resampled, y_true = resample(X_test, y_test)\n",
    "        \n",
    "        # get scores for each model\n",
    "        for model_name, Model in final_models:\n",
    "            \n",
    "            # keras model\n",
    "            if model_name == 'final_mlp':\n",
    "                auc = roc_auc_score(y_true, Model.predict(X_test_resampled))\n",
    "                results_auc[model_name].append(auc)\n",
    "                \n",
    "                y_pred = (Model.predict(X_test_resampled) > 0.5).astype(int)\n",
    "                \n",
    "                prec = precision_score(y_true, y_pred, zero_division = 0)\n",
    "                results_prec[model_name].append(prec)\n",
    "                recall = recall_score(y_true, y_pred)\n",
    "                results_recall[model_name].append(recall)\n",
    "                f1 = f1_score(y_true, y_pred)\n",
    "                results_f1[model_name].append(f1)\n",
    "                acc = accuracy_score(y_true, y_pred)\n",
    "                results_acc[model_name].append(acc) \n",
    "\n",
    "            # sklearn models\n",
    "            else:\n",
    "                auc = roc_auc_score(y_true, Model.predict_proba(X_test_resampled)[:, 1])\n",
    "                results_auc[model_name].append(auc)\n",
    "\n",
    "                y_pred = Model.predict(X_test_resampled)\n",
    "\n",
    "                prec = precision_score(y_true, y_pred, zero_division = 0)\n",
    "                results_prec[model_name].append(prec)\n",
    "                recall = recall_score(y_true, y_pred)\n",
    "                results_recall[model_name].append(recall)\n",
    "                f1 = f1_score(y_true, y_pred)\n",
    "                results_f1[model_name].append(f1)\n",
    "                acc = accuracy_score(y_true, y_pred)\n",
    "                results_acc[model_name].append(acc)    \n",
    "    \n",
    "    \n",
    "    # create data frames for each metric\n",
    "    pd.DataFrame(results_auc).to_pickle('test_results/df_auc.pkl')\n",
    "    pd.DataFrame(results_prec).to_pickle('test_results/df_prec.pkl')\n",
    "    pd.DataFrame(results_recall).to_pickle('test_results/df_recall.pkl')\n",
    "    pd.DataFrame(results_f1).to_pickle('test_results/df_f1.pkl')\n",
    "    pd.DataFrame(results_acc).to_pickle('test_results/df_acc.pkl')\n",
    "    \n",
    "    # create summary txt file with results\n",
    "    combined_results = [('auc', results_auc), ('prec', results_prec), ('recall', results_recall), \n",
    "                        ('f1', results_f1), ('acc', results_acc)]\n",
    "    result_file = open(fname, 'a')\n",
    "    for name, result in combined_results:\n",
    "        result_file.write('\\n\\n' + 'results for: ' + name + '\\n')\n",
    "        for model in result:\n",
    "            result_file.write(model + ': ' + str(np.median(result[model])))\n",
    "    result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83aa3610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating iteration no. 0...\n",
      "evaluating iteration no. 50...\n",
      "evaluating iteration no. 100...\n",
      "evaluating iteration no. 150...\n",
      "evaluating iteration no. 200...\n",
      "evaluating iteration no. 250...\n",
      "evaluating iteration no. 300...\n",
      "evaluating iteration no. 350...\n",
      "evaluating iteration no. 400...\n",
      "evaluating iteration no. 450...\n",
      "evaluating iteration no. 500...\n",
      "evaluating iteration no. 550...\n",
      "evaluating iteration no. 600...\n",
      "evaluating iteration no. 650...\n",
      "evaluating iteration no. 700...\n",
      "evaluating iteration no. 750...\n",
      "evaluating iteration no. 800...\n",
      "evaluating iteration no. 850...\n",
      "evaluating iteration no. 900...\n",
      "evaluating iteration no. 950...\n"
     ]
    }
   ],
   "source": [
    "# test models\n",
    "\n",
    "iter = 1000\n",
    "\n",
    "fname = 'test_results/test_summary' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "eval_model(final_models = final_models, n_iterations = iter, fname = fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26470752",
   "metadata": {},
   "source": [
    "## Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5123d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances for each sklearn model\n",
    "\n",
    "for model_name, Model in final_models:\n",
    "    if model_name != 'final_mlp':\n",
    "        feat_imp = permutation_importance(Model, X_test, y_test, n_repeats = 10)\n",
    "        feat_imp_df = pd.DataFrame(feat_imp.importances, index = X_test.columns.tolist())\n",
    "        feat_imp_df.to_pickle('test_results/feat_imp_{}.pkl'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7e0274",
   "metadata": {},
   "source": [
    "## Individual risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e77fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unprocessed testing data\n",
    "\n",
    "X_test = pd.read_pickle('X_test.pkl')\n",
    "y_test = pd.read_pickle('y_test.pkl')\n",
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a15c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_prediction(X_test):\n",
    "    \n",
    "    y = np.where(X_test['age'] < 55, 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75485873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diabetes_prediction(X_test):\n",
    "    \n",
    "    y = np.where(X_test['dm'] == 'Y', 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603dcdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nih_prediction(X_test, threshold):\n",
    "\n",
    "    y = np.where(X_test['nih_admit'] > threshold, 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e99f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revasc_prediction(X_test):\n",
    "    \n",
    "    y = np.where(X_test['time_to_reperf'] > 7, 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6742051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspects_prediction(X_test):\n",
    "    \n",
    "    y = np.where(X_test['aspects'] < 8, 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada98928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbe_score(X_test):\n",
    "    \n",
    "    aspects = np.where(X_test['aspects'] < 8, 1, 0)\n",
    "    \n",
    "    conditions = [X_test['nih_admit'] > 17, (X_test['nih_admit'] < 18) & (X_test['nih_admit'] > 8)]\n",
    "    choices = [2, 1]\n",
    "    nihss = np.select(conditions, choices, 0)\n",
    "    \n",
    "    collateral = np.where(X_test['coll_score'] < 2, 2, 0)\n",
    "    revasc = np.where((X_test['tici'] == '2B') | (X_test['tici'] == '3'), 0, 1)\n",
    "    \n",
    "    components = np.array([aspects, nihss, collateral, revasc])\n",
    "    mbe = components.sum(axis = 0)\n",
    "    \n",
    "    y = np.where(mbe > 3, 1, 0)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b2174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to evaluate risk factors\n",
    "\n",
    "def eval_scores(n_iterations):\n",
    "    \n",
    "    # create empty results dicts for each metric\n",
    "    results_auc = {'age': [], 'diabetes': [], 'nih_10': [], 'nih_15': [], 'nih_20': [], 'revasc': [], 'aspects': [], \n",
    "               'mbe': []}\n",
    "    results_acc = {'age': [], 'diabetes': [], 'nih_10': [], 'nih_15': [], 'nih_20': [], 'revasc': [], 'aspects': [], \n",
    "               'mbe': []}\n",
    "    \n",
    "    # bootstrap resample\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('evaluating iteration no. {}...'.format(i))\n",
    "        \n",
    "        X_test_resampled, y_true = resample(X_test, y_test)\n",
    "        \n",
    "        # get scores for each model\n",
    "        y_pred = age_prediction(X_test = X_test_resampled)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['age'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['age'].append(acc)\n",
    "        \n",
    "        y_pred = diabetes_prediction(X_test = X_test_resampled)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['diabetes'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['diabetes'].append(acc)\n",
    "        \n",
    "        y_pred = nih_prediction(X_test = X_test_resampled, threshold = 10)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['nih_10'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['nih_10'].append(acc)\n",
    "        \n",
    "        y_pred = nih_prediction(X_test = X_test_resampled, threshold = 15)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['nih_15'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['nih_15'].append(acc)\n",
    "        \n",
    "        y_pred = nih_prediction(X_test = X_test_resampled, threshold = 20)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['nih_20'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['nih_20'].append(acc)\n",
    "        \n",
    "        y_pred = revasc_prediction(X_test = X_test_resampled)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['revasc'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['revasc'].append(acc)\n",
    "        \n",
    "        y_pred = aspects_prediction(X_test = X_test_resampled)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['aspects'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['aspects'].append(acc)\n",
    "        \n",
    "        y_pred = mbe_score(X_test = X_test_resampled)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        results_auc['mbe'].append(auc)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        results_acc['mbe'].append(acc)\n",
    "        \n",
    "    results_auc = pd.DataFrame(results_auc)\n",
    "    results_acc = pd.DataFrame(results_acc)\n",
    "    results_auc.to_pickle('test_results/risk_factor_scores_auc.pkl')\n",
    "    results_acc.to_pickle('test_results/risk_factor_scores_acc.pkl')\n",
    "    \n",
    "    return results_auc, results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec5ff3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating iteration no. 0...\n",
      "evaluating iteration no. 50...\n",
      "evaluating iteration no. 100...\n",
      "evaluating iteration no. 150...\n",
      "evaluating iteration no. 200...\n",
      "evaluating iteration no. 250...\n",
      "evaluating iteration no. 300...\n",
      "evaluating iteration no. 350...\n",
      "evaluating iteration no. 400...\n",
      "evaluating iteration no. 450...\n",
      "evaluating iteration no. 500...\n",
      "evaluating iteration no. 550...\n",
      "evaluating iteration no. 600...\n",
      "evaluating iteration no. 650...\n",
      "evaluating iteration no. 700...\n",
      "evaluating iteration no. 750...\n",
      "evaluating iteration no. 800...\n",
      "evaluating iteration no. 850...\n",
      "evaluating iteration no. 900...\n",
      "evaluating iteration no. 950...\n"
     ]
    }
   ],
   "source": [
    "iter = 1000\n",
    "\n",
    "results_auc, results_acc = eval_scores(n_iterations = iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc598e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>nih_10</th>\n",
       "      <th>nih_15</th>\n",
       "      <th>nih_20</th>\n",
       "      <th>revasc</th>\n",
       "      <th>aspects</th>\n",
       "      <th>mbe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498242</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.549609</td>\n",
       "      <td>0.595851</td>\n",
       "      <td>0.476577</td>\n",
       "      <td>0.526335</td>\n",
       "      <td>0.548767</td>\n",
       "      <td>0.521589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.064799</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>0.065141</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>0.064881</td>\n",
       "      <td>0.083879</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.047246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.345070</td>\n",
       "      <td>0.320896</td>\n",
       "      <td>0.345833</td>\n",
       "      <td>0.328431</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.273881</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.452524</td>\n",
       "      <td>0.504681</td>\n",
       "      <td>0.505878</td>\n",
       "      <td>0.539566</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.494158</td>\n",
       "      <td>0.554125</td>\n",
       "      <td>0.553128</td>\n",
       "      <td>0.594363</td>\n",
       "      <td>0.472133</td>\n",
       "      <td>0.527115</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.518590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.540320</td>\n",
       "      <td>0.606370</td>\n",
       "      <td>0.592952</td>\n",
       "      <td>0.652364</td>\n",
       "      <td>0.518540</td>\n",
       "      <td>0.578358</td>\n",
       "      <td>0.584978</td>\n",
       "      <td>0.548007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.778595</td>\n",
       "      <td>0.815359</td>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.749183</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.790761</td>\n",
       "      <td>0.741013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age     diabetes       nih_10       nih_15       nih_20  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.498242     0.556858     0.549609     0.595851     0.476577   \n",
       "std       0.064799     0.078616     0.065141     0.081225     0.064881   \n",
       "min       0.345070     0.320896     0.345833     0.328431     0.326087   \n",
       "25%       0.452524     0.504681     0.505878     0.539566     0.429087   \n",
       "50%       0.494158     0.554125     0.553128     0.594363     0.472133   \n",
       "75%       0.540320     0.606370     0.592952     0.652364     0.518540   \n",
       "max       0.778595     0.815359     0.719697     0.833333     0.749183   \n",
       "\n",
       "            revasc      aspects          mbe  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.526335     0.548767     0.521589  \n",
       "std       0.083879     0.063448     0.047246  \n",
       "min       0.273881     0.392308     0.423077  \n",
       "25%       0.469697     0.503205     0.484375  \n",
       "50%       0.527115     0.550000     0.518590  \n",
       "75%       0.578358     0.584978     0.548007  \n",
       "max       0.818841     0.790761     0.741013  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_auc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac33dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>nih_10</th>\n",
       "      <th>nih_15</th>\n",
       "      <th>nih_20</th>\n",
       "      <th>revasc</th>\n",
       "      <th>aspects</th>\n",
       "      <th>mbe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.723727</td>\n",
       "      <td>0.700260</td>\n",
       "      <td>0.362273</td>\n",
       "      <td>0.569662</td>\n",
       "      <td>0.686636</td>\n",
       "      <td>0.574935</td>\n",
       "      <td>0.804779</td>\n",
       "      <td>0.829675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>0.054085</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.050455</td>\n",
       "      <td>0.055771</td>\n",
       "      <td>0.045620</td>\n",
       "      <td>0.041874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age     diabetes       nih_10       nih_15       nih_20  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.723727     0.700260     0.362273     0.569662     0.686636   \n",
       "std       0.050072     0.052429     0.054085     0.058326     0.050455   \n",
       "min       0.558442     0.532468     0.207792     0.324675     0.506494   \n",
       "25%       0.688312     0.662338     0.324675     0.532468     0.649351   \n",
       "50%       0.727273     0.701299     0.363636     0.571429     0.688312   \n",
       "75%       0.753247     0.740260     0.402597     0.610390     0.727273   \n",
       "max       0.870130     0.857143     0.558442     0.766234     0.831169   \n",
       "\n",
       "            revasc      aspects          mbe  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.574935     0.804779     0.829675  \n",
       "std       0.055771     0.045620     0.041874  \n",
       "min       0.389610     0.636364     0.688312  \n",
       "25%       0.532468     0.779221     0.805195  \n",
       "50%       0.571429     0.805195     0.831169  \n",
       "75%       0.610390     0.831169     0.857143  \n",
       "max       0.753247     0.935065     0.961039  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_acc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e61062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
