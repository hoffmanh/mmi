{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67173e76",
   "metadata": {},
   "source": [
    "# MMI prediction\n",
    "\n",
    "## 5. Training\n",
    "- Shortlist 10 models\n",
    "- Hyperparameter tuning top 3 + LR\n",
    "- Fit tuned models on entire training set and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ccac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline as make_pipeline_sk\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9609fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x7f8b3ef5d460>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.config_context(verbosity = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236d6f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 304 training samples\n"
     ]
    }
   ],
   "source": [
    "# load and shuffle data\n",
    "\n",
    "X_train = pd.read_pickle('X_train_trans.pkl')\n",
    "y_train = np.ravel(pd.read_pickle('y_train.pkl'))\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "print('There are {} training samples'.format(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d4d67",
   "metadata": {},
   "source": [
    "## Shortlist several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "029b8aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries of hyperparameters for sklearn and GBT models\n",
    "\n",
    "max_iter = 1000\n",
    "\n",
    "log_reg_params = [{'penalty': 'none', 'max_iter': max_iter}]\n",
    "dec_tree_params = [{'criterion': 'gini'}, {'criterion': 'entropy'}]\n",
    "rand_for_params = [{'criterion': 'gini'}, {'criterion': 'entropy'}]\n",
    "kneighbors_params = [{'n_neighbors': 3}, {'n_neighbors': 5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{'C': 0.01}, {'C': 0.1}, {'C': 1}, {'C': 10}]\n",
    "xgb_params = [{'use_label_encoder': False}]\n",
    "cb_params = [{'verbose': False}]\n",
    "lgbm_params = [{}]\n",
    "mlp_params = [{'hidden_layer_sizes': (10,), 'max_iter': max_iter}, {'hidden_layer_sizes': (10, 10,), 'max_iter': max_iter}, \n",
    "              {'hidden_layer_sizes': (10, 10, 10,), 'max_iter': max_iter}]\n",
    "\n",
    "models = [\n",
    "    ['log regression', LogisticRegression, log_reg_params],\n",
    "    ['decision tree', DecisionTreeClassifier, dec_tree_params],\n",
    "    ['random forest', RandomForestClassifier, rand_for_params],\n",
    "    ['k neighbors', KNeighborsClassifier, kneighbors_params],\n",
    "    ['naive bayes', GaussianNB, naive_bayes_params],\n",
    "    ['support vector machines', SVC, svc_params],\n",
    "    ['XG boost', xgb.XGBClassifier, xgb_params],\n",
    "    ['Cat boost', CatBoostClassifier, cb_params],\n",
    "    ['Light GBM', LGBMClassifier, lgbm_params],\n",
    "    ['MLP', MLPClassifier, mlp_params]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64532a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to evaluate sklearn and GBT models\n",
    "\n",
    "def eval_models(models, score, X_train, y_train, fname):\n",
    "    results = []\n",
    "    result_file = open(fname, 'a')\n",
    "    \n",
    "    for model_name, Model, params_list in models:\n",
    "        for params in params_list:\n",
    "            model = make_pipeline(\n",
    "                SMOTE(),\n",
    "                Model(**params)\n",
    "            )\n",
    "            cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 10)\n",
    "            scores = list(cross_val_score(model, X_train, y_train, scoring = score, cv = cv))\n",
    "            results.append((model_name, model, params, np.mean(scores), np.std(scores), scores))\n",
    "    \n",
    "    results.sort(key = lambda x:x[-3], reverse = True)\n",
    "    \n",
    "    # write score summary to txt file\n",
    "    result_file.write('\\nmean {} scores:\\n\\n'.format(score))\n",
    "    for modelname, model, params, mean, std, scores in results:\n",
    "        result_file.write(str(modelname) + '\\t' + str(params) + '\\t' + str(mean) + '\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    # write scores to dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for modelname, model, params, mean, std, scores in results:\n",
    "        column_name = str(modelname) + str(params)\n",
    "        df[column_name] = scores\n",
    "    df.to_pickle('experiments/init_training_results_{}.pkl'.format(score))\n",
    "    \n",
    "    # write permutation feature importances to dataframe\n",
    "    if score == 'roc_auc':\n",
    "        for modelname, model, params, mean, std, scores in results:\n",
    "            model.fit(X_train, y_train)\n",
    "            feat_imp = permutation_importance(model, X_train, y_train, n_repeats = 10)\n",
    "            feat_imp_df = pd.DataFrame(feat_imp.importances, index = X_train.columns.tolist())\n",
    "            feat_imp_df.to_pickle('experiments/init_training_feat_imp_{}.pkl'.format(modelname).replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4648658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:33:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:34:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:40:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:52:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# evaluate sklearn/GBT models\n",
    "\n",
    "scores = ['roc_auc', 'precision', 'recall', 'f1', 'accuracy']\n",
    "fname = 'experiments/init_training_summary' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "        \n",
    "for score in scores:\n",
    "    eval_models(models = models, score = score, X_train = X_train, y_train = y_train, fname = fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa691a49",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "287f7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested CV to find best parameters for sklearn models\n",
    "\n",
    "def eval_params(fname, tuning_model, param_grid):\n",
    "    \n",
    "    results = []\n",
    "    result_file = open(fname, 'a')\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    fold_no = 1\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "\n",
    "        X_train_split, X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_split, y_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        # find best model params\n",
    "        print('finding best model parameters for fold number {}'.format(fold_no))\n",
    "        model = make_pipeline(\n",
    "            SMOTE(),\n",
    "            tuning_model\n",
    "        )\n",
    "        grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 5, error_score = 'raise', \n",
    "                           scoring = 'roc_auc', verbose = 3)\n",
    "        grid_result = grid.fit(X_train_split, y_train_split)\n",
    "        \n",
    "        # evaluate best model params on outer fold\n",
    "        print('evaluating model for fold number {}'.format(fold_no))\n",
    "        best_params = grid_result.best_params_\n",
    "        print(best_params)\n",
    "        best_model = make_pipeline_sk(tuning_model)\n",
    "        best_model.set_params(**best_params)\n",
    "        best_model.fit(X_train_split, y_train_split)\n",
    "        score = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        results.append((best_params, score))\n",
    "        print('parameters: {}'.format(str(best_params)))\n",
    "        print('AUC score: {}'.format(score))\n",
    "        fold_no += 1\n",
    "\n",
    "    results.sort(key = lambda x:x[-1], reverse = True)\n",
    "    result_file.write('\\nAUC scores:\\n\\n')\n",
    "    \n",
    "    # write score summary to text file\n",
    "    for best_params, score in results:\n",
    "        result_file.write(str(best_params) + '\\t' + str(score) + '\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    # write scores to dataframe:\n",
    "    df = pd.DataFrame(results, columns = ['params', 'score'])\n",
    "    df.to_pickle('experiments/hyperparameter_tuning_results_{}.pkl'.format(tuning_model).replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define param grid for grid search - random forest\n",
    "\n",
    "n_estimators = [int(x) for x in range(20, 200, 20)] \n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10] \n",
    "min_samples_leaf = [1, 2, 4]\n",
    "rf_grid = {'randomforestclassifier__n_estimators': n_estimators, \n",
    "          'randomforestclassifier__max_features': max_features, \n",
    "          'randomforestclassifier__max_depth': max_depth, \n",
    "          'randomforestclassifier__min_samples_split': min_samples_split, \n",
    "          'randomforestclassifier__min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bbc5289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "evaluating model for fold number 1\n",
      "{'randomforestclassifier__max_depth': 60, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 60}\n",
      "parameters: {'randomforestclassifier__max_depth': 60, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 60}\n",
      "AUC score: 0.7488207547169812\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "evaluating model for fold number 2\n",
      "{'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 140}\n",
      "parameters: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 140}\n",
      "AUC score: 0.8372641509433962\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "evaluating model for fold number 3\n",
      "{'randomforestclassifier__max_depth': 90, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 100}\n",
      "parameters: {'randomforestclassifier__max_depth': 90, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 100}\n",
      "AUC score: 0.7358490566037736\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "evaluating model for fold number 4\n",
      "{'randomforestclassifier__max_depth': 80, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__n_estimators': 40}\n",
      "parameters: {'randomforestclassifier__max_depth': 80, 'randomforestclassifier__max_features': 'auto', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__n_estimators': 40}\n",
      "AUC score: 0.7287735849056605\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "evaluating model for fold number 5\n",
      "{'randomforestclassifier__max_depth': 60, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 40}\n",
      "parameters: {'randomforestclassifier__max_depth': 60, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 40}\n",
      "AUC score: 0.8113207547169811\n"
     ]
    }
   ],
   "source": [
    "# tune random forest\n",
    "\n",
    "fname = 'experiments/rf_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "eval_params(fname = fname, tuning_model = RandomForestClassifier(), param_grid = rf_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c367f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define param grid for grid search - SVM\n",
    "\n",
    "C = np.logspace(-2, 3, num = 6)\n",
    "gamma = np.logspace(-4, 0, num = 5)\n",
    "kernel = ['rbf']\n",
    "probability = [True]\n",
    "\n",
    "svm_grid = {'svc__C': C, \n",
    "           'svc__gamma': gamma, \n",
    "           'svc__kernel': kernel,\n",
    "           'svc__probability': probability}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0f1f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "evaluating model for fold number 1\n",
      "{'svc__C': 1000.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "parameters: {'svc__C': 1000.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "AUC score: 0.8089622641509434\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "evaluating model for fold number 2\n",
      "{'svc__C': 0.1, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "parameters: {'svc__C': 0.1, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "AUC score: 0.8160377358490566\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "evaluating model for fold number 3\n",
      "{'svc__C': 0.01, 'svc__gamma': 0.001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "parameters: {'svc__C': 0.01, 'svc__gamma': 0.001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "AUC score: 0.6627358490566038\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "evaluating model for fold number 4\n",
      "{'svc__C': 1.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "parameters: {'svc__C': 1.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "AUC score: 0.8419811320754718\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "evaluating model for fold number 5\n",
      "{'svc__C': 1000.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001, 'svc__kernel': 'rbf', 'svc__probability': True}\n",
      "AUC score: 0.8005390835579514\n"
     ]
    }
   ],
   "source": [
    "# tune SVM\n",
    "\n",
    "fname = 'experiments/svm_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "eval_params(fname = fname, tuning_model = SVC(), param_grid = svm_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1687ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define param grid for grid search - log reg\n",
    "\n",
    "penalty = ['l2', 'none']\n",
    "C = np.logspace(-2, 2, num = 5)\n",
    "max_iter = [1000]\n",
    "\n",
    "logreg_grid = {'logisticregression__penalty': penalty, \n",
    "              'logisticregression__C': C, \n",
    "              'logisticregression__max_iter': max_iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6b152d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "evaluating model for fold number 1\n",
      "{'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "AUC score: 0.8726415094339622\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/haydnhoffman/ml/my_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating model for fold number 2\n",
      "{'logisticregression__C': 100.0, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'none'}\n",
      "parameters: {'logisticregression__C': 100.0, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'none'}\n",
      "AUC score: 0.6320754716981132\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "evaluating model for fold number 3\n",
      "{'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "AUC score: 0.8018867924528302\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "evaluating model for fold number 4\n",
      "{'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "parameters: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "AUC score: 0.7122641509433962\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "evaluating model for fold number 5\n",
      "{'logisticregression__C': 10.0, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "parameters: {'logisticregression__C': 10.0, 'logisticregression__max_iter': 1000, 'logisticregression__penalty': 'l2'}\n",
      "AUC score: 0.7439353099730458\n"
     ]
    }
   ],
   "source": [
    "# tune logistic regression\n",
    "\n",
    "fname = 'experiments/logreg_tuning' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "\n",
    "eval_params(fname = fname, tuning_model = LogisticRegression(), param_grid = logreg_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bef0b4",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning - Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce7e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to build a keras DNN model\n",
    "\n",
    "def build_model(input_shape = X_train.shape[1], layer_size_factor = 3, num_hidden_layers = 1, dropout_rate = 0):\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = Dense(np.power(2, layer_size_factor), activation = 'relu')(inputs)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    if num_hidden_layers > 1:\n",
    "        for i in range(num_hidden_layers - 1):\n",
    "            x = Dense(np.power(2, layer_size_factor), activation = 'relu')(x)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile('adam', 'binary_crossentropy', metrics = [AUC()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c69a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define param grid for grid search\n",
    "\n",
    "sizes = np.arange(3, 9)\n",
    "layers = np.arange(1, 4) \n",
    "rates = np.arange(0, 0.6, 0.1)\n",
    "batch_size = [40, 60, 80, 100]\n",
    "epochs = [10, 50, 100] \n",
    "\n",
    "keras_grid = dict(kerasclassifier__layer_size_factor = sizes, \n",
    "                 kerasclassifier__num_hidden_layers = layers, \n",
    "                 kerasclassifier__dropout_rate = rates, \n",
    "                 kerasclassifier__batch_size = batch_size, \n",
    "                 kerasclassifier__epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "000c7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested CV to find best parameters for DNN model\n",
    "\n",
    "def eval_keras_params(fname, param_grid):\n",
    "\n",
    "    results = []\n",
    "    result_file = open(fname, 'a')\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    fold_no = 1\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "\n",
    "        X_train_split, X_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_split, y_test = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        # find best model params\n",
    "        print('finding best model parameters for fold number {}'.format(fold_no))\n",
    "        model = make_pipeline(\n",
    "            SMOTE(),\n",
    "            KerasClassifier(build_fn = build_model, input_shape = X_train_split.shape[1]) # wrapper for keras model\n",
    "        )\n",
    "        grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 5, error_score = 'raise', \n",
    "                           scoring = 'roc_auc', verbose = 2)\n",
    "        grid_result = grid.fit(X_train_split, y_train_split)\n",
    "    \n",
    "        # evaluate best model params on outer fold\n",
    "        print('evaluating model for fold number {}'.format(fold_no))\n",
    "        best_params = grid_result.best_params_\n",
    "        best_model = make_pipeline_sk(KerasClassifier(build_fn = build_model, input_shape = X_train_split.shape[1]))\n",
    "        best_model.set_params(**best_params)\n",
    "        best_model.fit(X_train_split, y_train_split)\n",
    "        score = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "        results.append((best_params, score))\n",
    "        print('parameters: {}'.format(str(best_params)))\n",
    "        print('AUC score: {}'.format(score))\n",
    "        fold_no += 1\n",
    "\n",
    "    results.sort(key = lambda x:x[-1], reverse = True)\n",
    "    result_file.write('\\nAUC scores:\\n\\n')\n",
    "    \n",
    "    # write score summary to text file\n",
    "    for best_params, score in results:\n",
    "        result_file.write(str(best_params) + '\\t' + str(score) + '\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    # write scores to dataframe:\n",
    "    df = pd.DataFrame(results, columns = ['params', 'score'])\n",
    "    df.to_pickle('experiments/hyperparameter_tuning_results_keras.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "25268306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best model parameters for fold number 1\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 0.8499 - auc_10: 0.5251\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8320 - auc_10: 0.4827\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7479 - auc_10: 0.5272\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7151 - auc_10: 0.5690\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7294 - auc_10: 0.5265\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7159 - auc_10: 0.5438\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7222 - auc_10: 0.5278\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7102 - auc_10: 0.5336\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6977 - auc_10: 0.5618\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6959 - auc_10: 0.5318\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7078 - auc_10: 0.5155\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6660 - auc_10: 0.6124\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6638 - auc_10: 0.6252\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6584 - auc_10: 0.6184\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6624 - auc_10: 0.6176\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6567 - auc_10: 0.6320\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6640 - auc_10: 0.6100\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6649 - auc_10: 0.6047\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6587 - auc_10: 0.6140\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6258 - auc_10: 0.7190\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6230 - auc_10: 0.7157\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6257 - auc_10: 0.6907\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6223 - auc_10: 0.6816\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6019 - auc_10: 0.7319\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6262 - auc_10: 0.6883\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6319 - auc_10: 0.6771\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5972 - auc_10: 0.7460\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6131 - auc_10: 0.6999\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6025 - auc_10: 0.7194\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5889 - auc_10: 0.7358\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6118 - auc_10: 0.7129\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5908 - auc_10: 0.7541\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5809 - auc_10: 0.7455\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5594 - auc_10: 0.7934\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5407 - auc_10: 0.8030\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5506 - auc_10: 0.8047\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5466 - auc_10: 0.8045\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5490 - auc_10: 0.7932\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5452 - auc_10: 0.7955\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5277 - auc_10: 0.8296\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5552 - auc_10: 0.7836\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5332 - auc_10: 0.8241\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5188 - auc_10: 0.8295\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5138 - auc_10: 0.8393\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5102 - auc_10: 0.8389\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5168 - auc_10: 0.8208\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4743 - auc_10: 0.8646\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5197 - auc_10: 0.8347\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4977 - auc_10: 0.8411\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4662 - auc_10: 0.8685\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4870 - auc_10: 0.8567\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4658 - auc_10: 0.8833\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4530 - auc_10: 0.8894\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4656 - auc_10: 0.8704\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4522 - auc_10: 0.8855\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4429 - auc_10: 0.8666\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4404 - auc_10: 0.8801\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4549 - auc_10: 0.8769\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3954 - auc_10: 0.9102\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4193 - auc_10: 0.8883\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4545 - auc_10: 0.8713\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4046 - auc_10: 0.9071\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4019 - auc_10: 0.8997\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3909 - auc_10: 0.9154\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3892 - auc_10: 0.9048\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4198 - auc_10: 0.8981\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4020 - auc_10: 0.9076\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3807 - auc_10: 0.9126\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4191 - auc_10: 0.8841\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3442 - auc_10: 0.9523\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3591 - auc_10: 0.9307\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3832 - auc_10: 0.9167\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3407 - auc_10: 0.9398\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3416 - auc_10: 0.9328\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3497 - auc_10: 0.9263\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3746 - auc_10: 0.9056\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3360 - auc_10: 0.9307\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3571 - auc_10: 0.9124\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3262 - auc_10: 0.9409\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3279 - auc_10: 0.9349\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3460 - auc_10: 0.9344\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3216 - auc_10: 0.9381\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3430 - auc_10: 0.9285\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3226 - auc_10: 0.9376\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3171 - auc_10: 0.9418\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3203 - auc_10: 0.9415\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3063 - auc_10: 0.9356\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3127 - auc_10: 0.9393\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2859 - auc_10: 0.9574\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3055 - auc_10: 0.9444\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2764 - auc_10: 0.9562\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2556 - auc_10: 0.9678\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2549 - auc_10: 0.9637\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2905 - auc_10: 0.9454\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2922 - auc_10: 0.9522\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2625 - auc_10: 0.9585\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2631 - auc_10: 0.9614\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2395 - auc_10: 0.9629\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2581 - auc_10: 0.9636\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2397 - auc_10: 0.9630\n",
      "evaluating model for fold number 1\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.6031 - auc_11: 0.4916\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5328 - auc_11: 0.5994\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5766 - auc_11: 0.5149\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5210 - auc_11: 0.5300\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5638 - auc_11: 0.4824\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5399 - auc_11: 0.4961\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4619 - auc_11: 0.6459\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4902 - auc_11: 0.5641\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4967 - auc_11: 0.5557\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5573 - auc_11: 0.4432\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5028 - auc_11: 0.5077\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4453 - auc_11: 0.6388\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4885 - auc_11: 0.5208\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4534 - auc_11: 0.5832\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4915 - auc_11: 0.5191\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4853 - auc_11: 0.5382\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4891 - auc_11: 0.5051\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4991 - auc_11: 0.4892\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4559 - auc_11: 0.5773\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4549 - auc_11: 0.5558\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4611 - auc_11: 0.5735\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4248 - auc_11: 0.6275\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4119 - auc_11: 0.6476\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4210 - auc_11: 0.6345\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4353 - auc_11: 0.6245\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4151 - auc_11: 0.6439\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4240 - auc_11: 0.6253\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3864 - auc_11: 0.7019\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4375 - auc_11: 0.5694\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4290 - auc_11: 0.6125\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4289 - auc_11: 0.6538\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4106 - auc_11: 0.6556\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4118 - auc_11: 0.6503\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4093 - auc_11: 0.6393\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4312 - auc_11: 0.5975\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4298 - auc_11: 0.6189\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3893 - auc_11: 0.6662\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3807 - auc_11: 0.6798\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4158 - auc_11: 0.6496\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4149 - auc_11: 0.6466\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4245 - auc_11: 0.6143\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3810 - auc_11: 0.6841\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4014 - auc_11: 0.6595\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3744 - auc_11: 0.7206\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3676 - auc_11: 0.7052\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3426 - auc_11: 0.7523\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3764 - auc_11: 0.7222\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3507 - auc_11: 0.7548\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3807 - auc_11: 0.6907\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3864 - auc_11: 0.6861\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3545 - auc_11: 0.7332\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3312 - auc_11: 0.7836\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3454 - auc_11: 0.7715\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3803 - auc_11: 0.6797\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3831 - auc_11: 0.6845\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3860 - auc_11: 0.7190\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3338 - auc_11: 0.7806\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3537 - auc_11: 0.7277\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3594 - auc_11: 0.7091\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3280 - auc_11: 0.7791\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3292 - auc_11: 0.7800\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3255 - auc_11: 0.7924\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3112 - auc_11: 0.8208\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3275 - auc_11: 0.7763\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3143 - auc_11: 0.8201\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3138 - auc_11: 0.8202\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3135 - auc_11: 0.8090\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3355 - auc_11: 0.7894\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3040 - auc_11: 0.8271\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3243 - auc_11: 0.7892\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3353 - auc_11: 0.7813\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3178 - auc_11: 0.7967\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3168 - auc_11: 0.8132\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3378 - auc_11: 0.8044\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3183 - auc_11: 0.7978\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3065 - auc_11: 0.8339\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2992 - auc_11: 0.8419\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3218 - auc_11: 0.8145\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3153 - auc_11: 0.8131\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2884 - auc_11: 0.8481\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2869 - auc_11: 0.8648\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2899 - auc_11: 0.8571\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2976 - auc_11: 0.8676\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3107 - auc_11: 0.8190\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2768 - auc_11: 0.8672\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2885 - auc_11: 0.8490\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2623 - auc_11: 0.9019\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3130 - auc_11: 0.8250\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2923 - auc_11: 0.8618\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2724 - auc_11: 0.8729\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2892 - auc_11: 0.8480\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2785 - auc_11: 0.8751\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2541 - auc_11: 0.9072\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2893 - auc_11: 0.8671\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2414 - auc_11: 0.9120\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2815 - auc_11: 0.8710\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2638 - auc_11: 0.8893\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2549 - auc_11: 0.9020\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2705 - auc_11: 0.8887\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2444 - auc_11: 0.9093\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc13ad6dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "parameters: {'kerasclassifier__batch_size': 100, 'kerasclassifier__dropout_rate': 0.30000000000000004, 'kerasclassifier__epochs': 100, 'kerasclassifier__layer_size_factor': 3, 'kerasclassifier__num_hidden_layers': 3}\n",
      "AUC score: 0.6768867924528301\n",
      "finding best model parameters for fold number 2\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 1s 1ms/step - loss: 0.7191 - auc_12: 0.6563\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6359 - auc_12: 0.7524\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5959 - auc_12: 0.8165\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5671 - auc_12: 0.8577\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5387 - auc_12: 0.8869\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5091 - auc_12: 0.9082\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4832 - auc_12: 0.9251\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4622 - auc_12: 0.9336\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4435 - auc_12: 0.9384\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4237 - auc_12: 0.9426\n",
      "evaluating model for fold number 2\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.6236 - auc_13: 0.4540\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5299 - auc_13: 0.4953\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4660 - auc_13: 0.5248\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4242 - auc_13: 0.5409\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3948 - auc_13: 0.5749\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3793 - auc_13: 0.6156\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3696 - auc_13: 0.6496\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3617 - auc_13: 0.6885\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3531 - auc_13: 0.7260\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3434 - auc_13: 0.7623\n",
      "parameters: {'kerasclassifier__batch_size': 100, 'kerasclassifier__dropout_rate': 0.0, 'kerasclassifier__epochs': 10, 'kerasclassifier__layer_size_factor': 5, 'kerasclassifier__num_hidden_layers': 1}\n",
      "AUC score: 0.6202830188679245\n",
      "finding best model parameters for fold number 3\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 2ms/step - loss: 0.8649 - auc_14: 0.5742\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7828 - auc_14: 0.6233\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7445 - auc_14: 0.5979\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7144 - auc_14: 0.6353\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7155 - auc_14: 0.6444\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7065 - auc_14: 0.6518\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6802 - auc_14: 0.6781\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6653 - auc_14: 0.6924\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6763 - auc_14: 0.6779\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6385 - auc_14: 0.7303\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6532 - auc_14: 0.7391\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6411 - auc_14: 0.7577\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6353 - auc_14: 0.7623\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6209 - auc_14: 0.7942\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6034 - auc_14: 0.8303\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5850 - auc_14: 0.8443\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5893 - auc_14: 0.8379\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5883 - auc_14: 0.8398\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5670 - auc_14: 0.8617\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5845 - auc_14: 0.8323\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5510 - auc_14: 0.8779\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5591 - auc_14: 0.8605\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5625 - auc_14: 0.8673\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5412 - auc_14: 0.8747\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5430 - auc_14: 0.8859\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5387 - auc_14: 0.8871\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5489 - auc_14: 0.8644\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5305 - auc_14: 0.8846\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5222 - auc_14: 0.8880\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5126 - auc_14: 0.9043\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5206 - auc_14: 0.8881\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5285 - auc_14: 0.8893\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5035 - auc_14: 0.9007\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4975 - auc_14: 0.8989\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5072 - auc_14: 0.8857\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5036 - auc_14: 0.8976\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4916 - auc_14: 0.9120\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4908 - auc_14: 0.9035\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4955 - auc_14: 0.9115\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4746 - auc_14: 0.9280\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4822 - auc_14: 0.9193\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4732 - auc_14: 0.9075\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4725 - auc_14: 0.9151\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4584 - auc_14: 0.9269\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4562 - auc_14: 0.9252\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4614 - auc_14: 0.9156\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4674 - auc_14: 0.9117\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4455 - auc_14: 0.9340\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4498 - auc_14: 0.9309\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4493 - auc_14: 0.9248\n",
      "evaluating model for fold number 3\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 1.6504 - auc_15: 0.5515\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4674 - auc_15: 0.5520\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.3407 - auc_15: 0.6304\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1284 - auc_15: 0.5739\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9598 - auc_15: 0.5961\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9332 - auc_15: 0.6131\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8413 - auc_15: 0.6038\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7592 - auc_15: 0.6282\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6999 - auc_15: 0.6511\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6671 - auc_15: 0.5741\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6116 - auc_15: 0.6042\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6076 - auc_15: 0.5508\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5777 - auc_15: 0.5361\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5646 - auc_15: 0.5860\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5232 - auc_15: 0.5587\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5230 - auc_15: 0.5264\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5203 - auc_15: 0.5712\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4978 - auc_15: 0.5285\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4539 - auc_15: 0.6246\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4517 - auc_15: 0.5914\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4714 - auc_15: 0.5533\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4483 - auc_15: 0.5797\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4397 - auc_15: 0.6547\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4083 - auc_15: 0.6281\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4543 - auc_15: 0.5846\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4568 - auc_15: 0.5443\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4122 - auc_15: 0.6491\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4352 - auc_15: 0.5689\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4689 - auc_15: 0.5320\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3981 - auc_15: 0.6519\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4159 - auc_15: 0.6579\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4157 - auc_15: 0.6208\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4488 - auc_15: 0.5560\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4224 - auc_15: 0.6192\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4097 - auc_15: 0.6364\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4071 - auc_15: 0.6177\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3725 - auc_15: 0.7161\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3588 - auc_15: 0.7484\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4198 - auc_15: 0.6192\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3850 - auc_15: 0.6845\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3891 - auc_15: 0.6851\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3968 - auc_15: 0.6834\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3673 - auc_15: 0.7228\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3951 - auc_15: 0.6586\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3727 - auc_15: 0.7203\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4056 - auc_15: 0.6649\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3686 - auc_15: 0.7144\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3949 - auc_15: 0.6795\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3839 - auc_15: 0.7117\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4090 - auc_15: 0.6686\n",
      "parameters: {'kerasclassifier__batch_size': 60, 'kerasclassifier__dropout_rate': 0.4, 'kerasclassifier__epochs': 50, 'kerasclassifier__layer_size_factor': 3, 'kerasclassifier__num_hidden_layers': 1}\n",
      "AUC score: 0.6603773584905661\n",
      "finding best model parameters for fold number 4\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 0.6505 - auc_16: 0.6648\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5143 - auc_16: 0.8802\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4145 - auc_16: 0.9275\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3577 - auc_16: 0.9385\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2940 - auc_16: 0.9546\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2380 - auc_16: 0.9732\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2235 - auc_16: 0.9731\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1986 - auc_16: 0.9782\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1502 - auc_16: 0.9883\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1324 - auc_16: 0.9928\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1174 - auc_16: 0.9952\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0842 - auc_16: 0.9987\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0863 - auc_16: 0.9985\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0784 - auc_16: 0.9985\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0621 - auc_16: 0.9985\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0429 - auc_16: 1.0000\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0478 - auc_16: 0.9995\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0330 - auc_16: 1.0000\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0342 - auc_16: 0.9997\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0288 - auc_16: 1.0000\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0243 - auc_16: 0.9999\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0210 - auc_16: 1.0000\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0162 - auc_16: 1.0000\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - auc_16: 1.0000\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0218 - auc_16: 0.9996\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0154 - auc_16: 1.0000\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0152 - auc_16: 1.0000\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0093 - auc_16: 1.0000\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - auc_16: 1.0000\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - auc_16: 1.0000\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - auc_16: 1.0000\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - auc_16: 1.0000\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0090 - auc_16: 1.0000\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - auc_16: 1.0000\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0136 - auc_16: 1.0000\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0043 - auc_16: 1.0000\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0060 - auc_16: 1.0000\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - auc_16: 1.0000\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - auc_16: 1.0000\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0065 - auc_16: 1.0000\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - auc_16: 1.0000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0039 - auc_16: 1.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0031 - auc_16: 1.0000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0041 - auc_16: 1.0000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0042 - auc_16: 1.0000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0029 - auc_16: 1.0000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - auc_16: 1.0000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0024 - auc_16: 1.0000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - auc_16: 1.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - auc_16: 1.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - auc_16: 1.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - auc_16: 1.0000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - auc_16: 1.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - auc_16: 1.0000\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - auc_16: 1.0000\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - auc_16: 1.0000\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0030 - auc_16: 1.0000\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0018 - auc_16: 1.0000\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - auc_16: 1.0000\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0064 - auc_16: 1.0000\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - auc_16: 1.0000\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - auc_16: 1.0000\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - auc_16: 1.0000\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - auc_16: 1.0000\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - auc_16: 1.0000\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - auc_16: 1.0000\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - auc_16: 1.0000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - auc_16: 1.0000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - auc_16: 1.0000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - auc_16: 1.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.8256e-04 - auc_16: 1.0000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - auc_16: 1.0000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - auc_16: 1.0000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.6815e-04 - auc_16: 1.0000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8593e-04 - auc_16: 1.0000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - auc_16: 1.0000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - auc_16: 1.0000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.1688e-04 - auc_16: 1.0000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - auc_16: 1.0000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.7217e-04 - auc_16: 1.0000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - auc_16: 1.0000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8940e-04 - auc_16: 1.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.4472e-04 - auc_16: 1.0000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.7446e-04 - auc_16: 1.0000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7403e-04 - auc_16: 1.0000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_16: 1.0000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.8482e-04 - auc_16: 1.0000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7665e-04 - auc_16: 1.0000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2125e-04 - auc_16: 1.0000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.0387e-04 - auc_16: 1.0000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5856e-04 - auc_16: 1.0000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.5648e-04 - auc_16: 1.0000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5797e-04 - auc_16: 1.0000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8868e-04 - auc_16: 1.0000\n",
      "evaluating model for fold number 4\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.5908 - auc_17: 0.4551\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3864 - auc_17: 0.5516\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4064 - auc_17: 0.6299\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3933 - auc_17: 0.7114\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3343 - auc_17: 0.8233\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2944 - auc_17: 0.8787\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2869 - auc_17: 0.8647\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2690 - auc_17: 0.8985\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2659 - auc_17: 0.9043\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2528 - auc_17: 0.9085\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2156 - auc_17: 0.9537\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2043 - auc_17: 0.9408\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2023 - auc_17: 0.9423\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1904 - auc_17: 0.9511\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1683 - auc_17: 0.9709\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1584 - auc_17: 0.9744\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1600 - auc_17: 0.9728\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1329 - auc_17: 0.9810\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1472 - auc_17: 0.9757\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1238 - auc_17: 0.9869\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1212 - auc_17: 0.9813\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0963 - auc_17: 0.9940\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1030 - auc_17: 0.9944\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0836 - auc_17: 0.9965\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0868 - auc_17: 0.9962\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0824 - auc_17: 0.9941\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0644 - auc_17: 0.9972\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0799 - auc_17: 0.9934\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0566 - auc_17: 0.9988\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0545 - auc_17: 0.9995\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0566 - auc_17: 0.9988\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0441 - auc_17: 0.9996\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0263 - auc_17: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0302 - auc_17: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0274 - auc_17: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0261 - auc_17: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0249 - auc_17: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0235 - auc_17: 0.9998\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0223 - auc_17: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0205 - auc_17: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0184 - auc_17: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0128 - auc_17: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0199 - auc_17: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0151 - auc_17: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0107 - auc_17: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0100 - auc_17: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0096 - auc_17: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0091 - auc_17: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0099 - auc_17: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0074 - auc_17: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0063 - auc_17: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0082 - auc_17: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0066 - auc_17: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0076 - auc_17: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0050 - auc_17: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0128 - auc_17: 0.9999\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0084 - auc_17: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0079 - auc_17: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0058 - auc_17: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0088 - auc_17: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0044 - auc_17: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0054 - auc_17: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0055 - auc_17: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0036 - auc_17: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0068 - auc_17: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0040 - auc_17: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0040 - auc_17: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0093 - auc_17: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0035 - auc_17: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0050 - auc_17: 1.0000\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0031 - auc_17: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0028 - auc_17: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0032 - auc_17: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0027 - auc_17: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0021 - auc_17: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0028 - auc_17: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0025 - auc_17: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0047 - auc_17: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0019 - auc_17: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0014 - auc_17: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0017 - auc_17: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0024 - auc_17: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0024 - auc_17: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0013 - auc_17: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0011 - auc_17: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0026 - auc_17: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0015 - auc_17: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0019 - auc_17: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0011 - auc_17: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0016 - auc_17: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0021 - auc_17: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0020 - auc_17: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0012 - auc_17: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 9.8860e-04 - auc_17: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0017 - auc_17: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0013 - auc_17: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0014 - auc_17: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0023 - auc_17: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 6.0217e-04 - auc_17: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0015 - auc_17: 1.0000\n",
      "parameters: {'kerasclassifier__batch_size': 100, 'kerasclassifier__dropout_rate': 0.30000000000000004, 'kerasclassifier__epochs': 100, 'kerasclassifier__layer_size_factor': 8, 'kerasclassifier__num_hidden_layers': 2}\n",
      "AUC score: 0.7028301886792453\n",
      "finding best model parameters for fold number 5\n",
      "Fitting 5 folds for each of 1296 candidates, totalling 6480 fits\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 3ms/step - loss: 0.6860 - auc_18: 0.5848\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7006 - auc_18: 0.5714\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - auc_18: 0.5680\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7040 - auc_18: 0.6022\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6860 - auc_18: 0.5830\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6825 - auc_18: 0.5961\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6796 - auc_18: 0.6308\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6836 - auc_18: 0.6262\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6669 - auc_18: 0.6361\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6353 - auc_18: 0.7059\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6448 - auc_18: 0.6823\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6517 - auc_18: 0.6786\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6388 - auc_18: 0.7068\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6391 - auc_18: 0.7131\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6327 - auc_18: 0.7329\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6293 - auc_18: 0.7264\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6125 - auc_18: 0.7417\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6213 - auc_18: 0.7306\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6079 - auc_18: 0.7558\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6177 - auc_18: 0.7228\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5969 - auc_18: 0.7885\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5801 - auc_18: 0.8014\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6021 - auc_18: 0.7557\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5986 - auc_18: 0.7746\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5704 - auc_18: 0.7998\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5856 - auc_18: 0.7870\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5749 - auc_18: 0.8016\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5406 - auc_18: 0.8467\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5298 - auc_18: 0.8453\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5219 - auc_18: 0.8464\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5352 - auc_18: 0.8220\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5490 - auc_18: 0.8161\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5390 - auc_18: 0.8245\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4947 - auc_18: 0.8560\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5279 - auc_18: 0.8249\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4825 - auc_18: 0.8787\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4995 - auc_18: 0.8540\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4717 - auc_18: 0.8733\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4711 - auc_18: 0.8723\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4352 - auc_18: 0.8947\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4358 - auc_18: 0.8929\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4859 - auc_18: 0.8683\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4721 - auc_18: 0.8681\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4481 - auc_18: 0.8902\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4225 - auc_18: 0.8965\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4166 - auc_18: 0.9062\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4219 - auc_18: 0.9032\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4037 - auc_18: 0.9071\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4489 - auc_18: 0.8742\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3732 - auc_18: 0.9247\n",
      "evaluating model for fold number 5\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.8724 - auc_19: 0.5557\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7928 - auc_19: 0.6464\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8114 - auc_19: 0.5540\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7838 - auc_19: 0.4301\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7544 - auc_19: 0.5235\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7319 - auc_19: 0.4522\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6816 - auc_19: 0.5182\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6831 - auc_19: 0.4337\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6827 - auc_19: 0.4917\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6239 - auc_19: 0.5281\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6531 - auc_19: 0.4806\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6400 - auc_19: 0.5009\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6038 - auc_19: 0.5366\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6221 - auc_19: 0.3955\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6553 - auc_19: 0.3815\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6297 - auc_19: 0.4499\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5707 - auc_19: 0.5441\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6138 - auc_19: 0.4968\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5647 - auc_19: 0.4999\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5960 - auc_19: 0.4350\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5596 - auc_19: 0.5670\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5325 - auc_19: 0.6022\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5492 - auc_19: 0.5194\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5435 - auc_19: 0.5198\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4955 - auc_19: 0.6247\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5523 - auc_19: 0.4777\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5950 - auc_19: 0.3633\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4850 - auc_19: 0.6199\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4803 - auc_19: 0.6270\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5341 - auc_19: 0.5285\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5236 - auc_19: 0.5356\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4925 - auc_19: 0.5344\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5145 - auc_19: 0.5220\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4951 - auc_19: 0.5663\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5041 - auc_19: 0.5244\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4916 - auc_19: 0.5591\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4502 - auc_19: 0.6265\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4628 - auc_19: 0.5935\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4918 - auc_19: 0.5294\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4244 - auc_19: 0.6198\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4692 - auc_19: 0.5554\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4312 - auc_19: 0.6576\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4088 - auc_19: 0.6662\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4895 - auc_19: 0.5045\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4820 - auc_19: 0.5308\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4371 - auc_19: 0.6088\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4511 - auc_19: 0.5926\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4310 - auc_19: 0.6504\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4236 - auc_19: 0.6279\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4072 - auc_19: 0.6267\n",
      "parameters: {'kerasclassifier__batch_size': 100, 'kerasclassifier__dropout_rate': 0.4, 'kerasclassifier__epochs': 50, 'kerasclassifier__layer_size_factor': 4, 'kerasclassifier__num_hidden_layers': 3}\n",
      "AUC score: 0.7439353099730458\n"
     ]
    }
   ],
   "source": [
    "fname = 'experiments/keras_models' + '_' + str(datetime.now().year) + '_' + str(datetime.now().month) \\\n",
    "    + '_' + str(datetime.now().day) + '_' + str(datetime.now().hour) + '_' + \\\n",
    "    str(datetime.now().minute) + '.txt'\n",
    "    \n",
    "eval_keras_params(fname = fname, param_grid = keras_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4139d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters based on tuning\n",
    "\n",
    "keras_params = {'layer_size_factor': 4, \n",
    "             'num_hidden_layers': 3,\n",
    "             'dropout_rate': 0.4}\n",
    "svm_params = {'C': 1, \n",
    "             'gamma': 0.0001, \n",
    "             'kernel': 'rbf', \n",
    "             'probability': True}\n",
    "rf_params = {'max_depth': None,\n",
    "            'max_features': 'auto', \n",
    "            'min_samples_leaf': 2, \n",
    "            'min_samples_split': 5, \n",
    "            'n_estimators': 140}\n",
    "logreg_params = {'C': 0.1,\n",
    "                'max_iter': 1000, \n",
    "                'penalty': 'l2'}\n",
    "\n",
    "final_models = [\n",
    "    ['svm', SVC(**svm_params)],\n",
    "    ['rf', RandomForestClassifier(**rf_params)], \n",
    "    ['logreg', LogisticRegression(**logreg_params)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0676c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to fit model and save it\n",
    "\n",
    "def fit_save_model(name, model, X, y):\n",
    "    print('fitting {}'.format(name))\n",
    "    model.fit(X, y)\n",
    "    fname = 'models/final_{}.sav'.format(name)\n",
    "    pickle.dump(model, open(fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99111537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit final models on all training data and save\n",
    "\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "for name, model in final_models:\n",
    "    fit_save_model(name = name, model = model, X = X_res, y = y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f69646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 83)]              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1344      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,905\n",
      "Trainable params: 1,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 2ms/step - loss: 0.8705 - auc_3: 0.5243\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7870 - auc_3: 0.5113\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7340 - auc_3: 0.5819\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7126 - auc_3: 0.5596\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.7206 - auc_3: 0.5621\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.7091 - auc_3: 0.5454\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6975 - auc_3: 0.5474\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6887 - auc_3: 0.5740\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6822 - auc_3: 0.5623\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6995 - auc_3: 0.5623\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6836 - auc_3: 0.5513\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6687 - auc_3: 0.5875\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6553 - auc_3: 0.6285\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6658 - auc_3: 0.6273\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6674 - auc_3: 0.5877\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6541 - auc_3: 0.6354\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6473 - auc_3: 0.6679\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6597 - auc_3: 0.6289\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6532 - auc_3: 0.6532\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6326 - auc_3: 0.7039\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6382 - auc_3: 0.6740\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6270 - auc_3: 0.6949\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6124 - auc_3: 0.7094\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6043 - auc_3: 0.7195\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5938 - auc_3: 0.7450\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5915 - auc_3: 0.7308\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5639 - auc_3: 0.7859\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6059 - auc_3: 0.7258\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5590 - auc_3: 0.8019\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5806 - auc_3: 0.7646\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5858 - auc_3: 0.7603\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5548 - auc_3: 0.7924\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5071 - auc_3: 0.8371\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5154 - auc_3: 0.8248\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4798 - auc_3: 0.8634\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4713 - auc_3: 0.8674\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4839 - auc_3: 0.8431\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4946 - auc_3: 0.8580\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4618 - auc_3: 0.8698\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4583 - auc_3: 0.8709\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4681 - auc_3: 0.8621\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4657 - auc_3: 0.8719\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4265 - auc_3: 0.8949\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4439 - auc_3: 0.8719\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4054 - auc_3: 0.9129\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4077 - auc_3: 0.9071\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4074 - auc_3: 0.9045\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4009 - auc_3: 0.9045\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3731 - auc_3: 0.9185\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.3916 - auc_3: 0.9088\n",
      "INFO:tensorflow:Assets written to: models/final_mlp/assets\n"
     ]
    }
   ],
   "source": [
    "# fit keras model on all training data and save\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "\n",
    "final_mlp = build_model(input_shape = X_train.shape[1], **keras_params)\n",
    "final_mlp.summary()\n",
    "final_mlp.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [AUC()])\n",
    "final_mlp.fit(X_res, y_res, batch_size = batch_size, epochs = epochs)\n",
    "final_mlp.save('models/final_mlp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
